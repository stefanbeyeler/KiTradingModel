# =============================================================================
# KI Trading Model - Microservices Docker Compose
# =============================================================================
# Resource Allocation Strategy (14 CPU cores, 122 GB RAM):
#
# HIGH PRIORITY (API responses - always responsive):
#   - frontend:     1 CPU,   512MB  (nginx proxy)
#   - data:         2 CPU,   4GB    (central data gateway)
#   - hmm:          2 CPU,   4GB    (regime detection - inference)
#   - embedder:     2 CPU,   12GB   (embedding service)
#   - rag:          2 CPU,   8GB    (vector search)
#   - llm:          2 CPU,   4GB    (API proxy to Ollama)
#   - tcn:          2 CPU,   4GB    (chart pattern detection - inference)
#   - candlestick:  2 CPU,   2GB    (candlestick pattern detection - inference)
#   - nhits:        2 CPU,   4GB    (price forecasting - inference only)
#   - watchdog:     1 CPU,   1GB    (monitoring + training orchestrator)
#
# LOW PRIORITY (Training - uses remaining resources, orchestrated by Watchdog):
#   - nhits-train:       4 CPU,   16GB  (with nice priority)
#   - tcn-train:         4 CPU,   8GB   (with nice priority)
#   - hmm-train:         2 CPU,   4GB   (with nice priority)
#   - candlestick-train: 2 CPU,   4GB   (with nice priority)
#
# Total Reserved: ~28 CPUs (with overcommit), ~75 GB RAM
# Remaining for system: ~47 GB RAM
# =============================================================================

# Build version info - set via environment or defaults
# Usage: BUILD_VERSION=1.0.0.123+abc1234 docker-compose up --build
x-build-info: &build-info
  BUILD_VERSION: ${BUILD_VERSION:-}
  BUILD_COMMIT: ${BUILD_COMMIT:-}
  BUILD_DATE: ${BUILD_DATE:-}
  BUILD_NUMBER: ${BUILD_NUMBER:-}

services:
  # =========================================================================
  # INFRASTRUCTURE SERVICES - Redis Cache
  # =========================================================================

  # Redis Cache - Zentraler Cache f√ºr alle Services
  redis:
    image: redis:7-alpine
    container_name: trading-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    networks:
      - trading-net
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3
      start_period: 5s

  # =========================================================================
  # HIGH PRIORITY SERVICES - Always responsive for API requests
  # =========================================================================

  # Frontend - API Gateway & Dashboard (Port 3000)
  frontend:
    build:
      context: .
      dockerfile: docker/services/frontend/Dockerfile
      args:
        - DATA_SERVICE_PORT=${DATA_SERVICE_PORT:-3001}
        - NHITS_SERVICE_PORT=${NHITS_SERVICE_PORT:-3002}
        - TCN_SERVICE_PORT=${TCN_SERVICE_PORT:-3003}
        - HMM_SERVICE_PORT=${HMM_SERVICE_PORT:-3004}
        - EMBEDDER_SERVICE_PORT=${EMBEDDER_SERVICE_PORT:-3005}
        - RAG_SERVICE_PORT=${RAG_SERVICE_PORT:-3008}
        - LLM_SERVICE_PORT=${LLM_SERVICE_PORT:-3009}
        - WATCHDOG_SERVICE_PORT=${WATCHDOG_SERVICE_PORT:-3010}
    container_name: trading-frontend
    ports:
      - "3000:80"
    volumes:
      - ./docker/services/frontend/html:/usr/share/nginx/html:ro
    environment:
      - DATA_SERVICE_PORT=${DATA_SERVICE_PORT:-3001}
      - NHITS_SERVICE_PORT=${NHITS_SERVICE_PORT:-3002}
      - TCN_SERVICE_PORT=${TCN_SERVICE_PORT:-3003}
      - HMM_SERVICE_PORT=${HMM_SERVICE_PORT:-3004}
      - EMBEDDER_SERVICE_PORT=${EMBEDDER_SERVICE_PORT:-3005}
      - CANDLESTICK_SERVICE_PORT=${CANDLESTICK_SERVICE_PORT:-3006}
      - RAG_SERVICE_PORT=${RAG_SERVICE_PORT:-3008}
      - LLM_SERVICE_PORT=${LLM_SERVICE_PORT:-3009}
      - WATCHDOG_SERVICE_PORT=${WATCHDOG_SERVICE_PORT:-3010}
      - CANDLESTICK_TRAIN_SERVICE_PORT=${CANDLESTICK_TRAIN_SERVICE_PORT:-3016}
    depends_on:
      - nhits-service
      - data-service
    networks:
      - trading-net
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
    healthcheck:
      test: ["CMD", "curl", "-f", "-s", "http://localhost/health"]
      interval: 30s
      timeout: 3s
      retries: 3

  # Data Service - Symbols, Strategies, Sync (CRITICAL - all services depend on this)
  data-service:
    build:
      context: .
      dockerfile: docker/services/data/Dockerfile
      args:
        - SERVICE_PORT=${DATA_SERVICE_PORT:-3001}
    container_name: trading-data
    ports:
      - "${DATA_SERVICE_PORT:-3001}:${DATA_SERVICE_PORT:-3001}"
    volumes:
      - data-storage:/app/data
      - symbols-data:/app/data/symbols
      - faiss-data:/app/data/faiss
      - ./src:/app/src:ro
      - ./tests:/app/tests:ro
      - ./pytest.ini:/app/pytest.ini:ro
      - logs-data:/app/logs
      - /tmp:/host_tmp:ro
    environment:
      - SERVICE_NAME=data
      - PROJECT_ROOT=/app
      - PORT=${DATA_SERVICE_PORT:-3001}
      - ROOT_PATH=/data
      - EASYINSIGHT_API_URL=${EASYINSIGHT_API_URL:-http://10.1.19.102:3000/api}
      - OLLAMA_HOST=http://host.docker.internal:11434
      - FAISS_PERSIST_DIRECTORY=/app/data/faiss
      - REDIS_URL=redis://trading-redis:6379
      # TimescaleDB Configuration
      - TIMESCALE_HOST=${TIMESCALE_HOST:-10.1.19.102}
      - TIMESCALE_PORT=${TIMESCALE_PORT:-5432}
      - TIMESCALE_DATABASE=${TIMESCALE_DATABASE:-tradingdataservice}
      - TIMESCALE_USER=${TIMESCALE_USER:-postgres}
      - TIMESCALE_PASSWORD=${TIMESCALE_PASSWORD:-postgres}
      - TIMESCALE_POOL_MIN=${TIMESCALE_POOL_MIN:-5}
      - TIMESCALE_POOL_MAX=${TIMESCALE_POOL_MAX:-20}
      - TIMESCALE_ENABLED=${TIMESCALE_ENABLED:-true}
      # Build version info
      - BUILD_VERSION=${BUILD_VERSION:-}
      - BUILD_COMMIT=${BUILD_COMMIT:-}
      - BUILD_DATE=${BUILD_DATE:-}
      - BUILD_NUMBER=${BUILD_NUMBER:-}
    depends_on:
      - redis
    networks:
      - trading-net
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${DATA_SERVICE_PORT:-3001}/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  # HMM-Regime Service - Market Regime Detection & Signal Scoring (Port 3004)
  hmm-service:
    build:
      context: .
      dockerfile: docker/services/hmm/Dockerfile
      args:
        - SERVICE_PORT=${HMM_SERVICE_PORT:-3004}
    container_name: trading-hmm
    ports:
      - "${HMM_SERVICE_PORT:-3004}:${HMM_SERVICE_PORT:-3004}"
    volumes:
      - hmm-models:/app/data/models/hmm
      - symbols-data:/app/data/symbols
      - ./src/services/hmm_app:/app/src/services/hmm_app:ro
      - ./src/services/data_gateway_service.py:/app/src/services/data_gateway_service.py:ro
      - ./src/shared:/app/src/shared:ro
      - ./src/config:/app/src/config:ro
      - logs-data:/app/logs
    environment:
      - SERVICE_NAME=hmm
      - PORT=${HMM_SERVICE_PORT:-3004}
      - ROOT_PATH=/hmm
      - DATA_SERVICE_URL=http://trading-data:${DATA_SERVICE_PORT:-3001}
    networks:
      - trading-net
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    depends_on:
      - data-service
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${HMM_SERVICE_PORT:-3004}/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Embedder Service - Central Embedding Service (Port 3005)
  embedder-service:
    build:
      context: .
      dockerfile: docker/services/embedder/Dockerfile
      args:
        - SERVICE_PORT=${EMBEDDER_SERVICE_PORT:-3005}
    container_name: trading-embedder
    runtime: nvidia
    ports:
      - "${EMBEDDER_SERVICE_PORT:-3005}:${EMBEDDER_SERVICE_PORT:-3005}"
    volumes:
      - embedder-models:/app/data/models/embedder
      - embedder-cache:/app/cache
      - ./src/services/embedder_app:/app/src/services/embedder_app:ro
      - ./src/services/data_gateway_service.py:/app/src/services/data_gateway_service.py:ro
      - ./src/shared:/app/src/shared:ro
      - ./src/config:/app/src/config:ro
      - logs-data:/app/logs
    environment:
      - SERVICE_NAME=embedder
      - PORT=${EMBEDDER_SERVICE_PORT:-3005}
      - ROOT_PATH=/embedder
      - DATA_SERVICE_URL=http://trading-data:${DATA_SERVICE_PORT:-3001}
      - EMBEDDING_CACHE_SIZE=10000
    networks:
      - trading-net
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    depends_on:
      - data-service
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 12G
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${EMBEDDER_SERVICE_PORT:-3005}/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

  # RAG Service - Vector Search & Knowledge Base (Port 3008)
  rag-service:
    build:
      context: .
      dockerfile: docker/services/rag/Dockerfile
      args:
        - SERVICE_PORT=${RAG_SERVICE_PORT:-3008}
    container_name: trading-rag
    runtime: nvidia
    ports:
      - "${RAG_SERVICE_PORT:-3008}:${RAG_SERVICE_PORT:-3008}"
    volumes:
      - rag-faiss:/app/data/faiss
      - symbols-data:/app/data/symbols
      - ./src:/app/src:ro
      - logs-data:/app/logs
    environment:
      - SERVICE_NAME=rag
      - PORT=${RAG_SERVICE_PORT:-3008}
      - ROOT_PATH=/rag
      - FAISS_USE_GPU=1
      - EMBEDDING_DEVICE=cuda
      - FAISS_PERSIST_DIRECTORY=/app/data/faiss
      # Data Service Gateway
      - DATA_SERVICE_URL=http://trading-data:${DATA_SERVICE_PORT:-3001}
      # ML Inference Service URLs
      - NHITS_SERVICE_URL=http://trading-nhits:${NHITS_SERVICE_PORT:-3002}
      - TCN_SERVICE_URL=http://trading-tcn:${TCN_SERVICE_PORT:-3003}
      - HMM_SERVICE_URL=http://trading-hmm:${HMM_SERVICE_PORT:-3004}
      - EMBEDDER_SERVICE_URL=http://trading-embedder:${EMBEDDER_SERVICE_PORT:-3005}
      - CANDLESTICK_SERVICE_URL=http://trading-candlestick:${CANDLESTICK_SERVICE_PORT:-3006}
      - CNN_LSTM_SERVICE_URL=http://trading-cnn-lstm:${CNN_LSTM_SERVICE_PORT:-3007}
      # Build version info
      - BUILD_VERSION=${BUILD_VERSION:-}
      - BUILD_COMMIT=${BUILD_COMMIT:-}
      - BUILD_DATE=${BUILD_DATE:-}
      - BUILD_NUMBER=${BUILD_NUMBER:-}
    networks:
      - trading-net
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    depends_on:
      - data-service
      - nhits-service
      - tcn-service
      - hmm-service
      - embedder-service
      - candlestick-service
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 8G
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${RAG_SERVICE_PORT:-3008}/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # LLM Service - Analysis & RAG (Port 3009)
  llm-service:
    build:
      context: .
      dockerfile: docker/services/llm/Dockerfile
      args:
        - SERVICE_PORT=${LLM_SERVICE_PORT:-3009}
    container_name: trading-llm
    runtime: nvidia
    ports:
      - "${LLM_SERVICE_PORT:-3009}:${LLM_SERVICE_PORT:-3009}"
    volumes:
      - rag-faiss:/app/data/rag
      - symbols-data:/app/data/symbols
      - ./src:/app/src:ro
      - logs-data:/app/logs
    environment:
      - SERVICE_NAME=llm
      - PORT=${LLM_SERVICE_PORT:-3009}
      - ROOT_PATH=/llm
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.1:70b}
      - OLLAMA_HOST=http://host.docker.internal:11434
      - FAISS_USE_GPU=1
      - EMBEDDING_DEVICE=cuda
      - EASYINSIGHT_API_URL=${EASYINSIGHT_API_URL:-http://10.1.19.102:3000/api}
      # Build version info
      - BUILD_VERSION=${BUILD_VERSION:-}
      - BUILD_COMMIT=${BUILD_COMMIT:-}
      - BUILD_DATE=${BUILD_DATE:-}
      - BUILD_NUMBER=${BUILD_NUMBER:-}
    networks:
      - trading-net
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    depends_on:
      - rag-service
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${LLM_SERVICE_PORT:-3009}/health"]
      interval: 30s
      timeout: 30s
      retries: 3
      start_period: 60s

  # =========================================================================
  # LOW PRIORITY SERVICES - Training tasks, use remaining resources
  # =========================================================================

  # NHITS Service - Training & Forecasting (LOW PRIORITY for training)
  nhits-service:
    build:
      context: .
      dockerfile: docker/services/nhits/Dockerfile
      args:
        - SERVICE_PORT=${NHITS_SERVICE_PORT:-3002}
    container_name: trading-nhits
    runtime: nvidia
    ports:
      - "${NHITS_SERVICE_PORT:-3002}:${NHITS_SERVICE_PORT:-3002}"
    volumes:
      - nhits-models:/app/data/models/nhits
      - nhits-feedback:/app/data/model_feedback
      - nhits-metrics:/app/data/model_metrics
      - symbols-data:/app/data/symbols
      - ./src:/app/src:ro
      - logs-data:/app/logs
      - /tmp:/host_tmp:ro
    environment:
      - SERVICE_NAME=nhits
      - PORT=${NHITS_SERVICE_PORT:-3002}
      - ROOT_PATH=/nhits
      - NHITS_USE_GPU=1
      - EASYINSIGHT_API_URL=${EASYINSIGHT_API_URL:-http://10.1.19.102:3000/api}
      - NHITS_AUTO_RETRAIN_DAYS=${NHITS_AUTO_RETRAIN_DAYS:-7}
      - OLLAMA_HOST=http://host.docker.internal:11434
      - DATA_SERVICE_URL=http://trading-data:${DATA_SERVICE_PORT:-3001}
      # Limit CPU threads for training to prevent blocking
      - OMP_NUM_THREADS=4
      - MKL_NUM_THREADS=4
      - OPENBLAS_NUM_THREADS=4
      - NUMEXPR_MAX_THREADS=4
      # Build version info
      - BUILD_VERSION=${BUILD_VERSION:-}
      - BUILD_COMMIT=${BUILD_COMMIT:-}
      - BUILD_DATE=${BUILD_DATE:-}
      - BUILD_NUMBER=${BUILD_NUMBER:-}
    networks:
      - trading-net
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 16G
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${NHITS_SERVICE_PORT:-3002}/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # TCN-Pattern Service - Chart Pattern Detection (INFERENCE ONLY)
  # Training is handled by the separate tcn-train-service
  tcn-service:
    build:
      context: .
      dockerfile: docker/services/tcn/Dockerfile
      args:
        - SERVICE_PORT=${TCN_SERVICE_PORT:-3003}
    container_name: trading-tcn
    runtime: nvidia
    ports:
      - "${TCN_SERVICE_PORT:-3003}:${TCN_SERVICE_PORT:-3003}"
    volumes:
      - tcn-models:/app/data/models/tcn
      - tcn-data:/app/data/tcn
      - symbols-data:/app/data/symbols
      - ./src/services/tcn_app:/app/src/services/tcn_app:ro
      - ./src/services/data_gateway_service.py:/app/src/services/data_gateway_service.py:ro
      - ./src/shared:/app/src/shared:ro
      - ./src/config:/app/src/config:ro
      - logs-data:/app/logs
    environment:
      - SERVICE_NAME=tcn
      - PORT=${TCN_SERVICE_PORT:-3003}
      - ROOT_PATH=/tcn
      - DATA_SERVICE_URL=http://trading-data:${DATA_SERVICE_PORT:-3001}
      - EMBEDDER_SERVICE_URL=http://trading-embedder:${EMBEDDER_SERVICE_PORT:-3005}
      - TCN_MODEL_PATH=/app/data/models/tcn/latest.pt
      - TCN_AUTO_SCAN=true
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
    networks:
      - trading-net
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    depends_on:
      - data-service
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${TCN_SERVICE_PORT:-3003}/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Candlestick Pattern Service - Candlestick Pattern Detection (INFERENCE)
  # Port 3006 - Detects candlestick patterns like Hammer, Doji, Engulfing etc.
  candlestick-service:
    build:
      context: .
      dockerfile: docker/services/candlestick/Dockerfile
    container_name: trading-candlestick
    ports:
      - "${CANDLESTICK_SERVICE_PORT:-3006}:${CANDLESTICK_SERVICE_PORT:-3006}"
    volumes:
      - candlestick-data:/app/data
      - ./src/services/candlestick_app:/app/src/services/candlestick_app:ro
      - logs-data:/app/logs
    environment:
      - SERVICE_NAME=candlestick
      - PORT=${CANDLESTICK_SERVICE_PORT:-3006}
      - ROOT_PATH=/candlestick
      - DATA_SERVICE_URL=http://trading-data:${DATA_SERVICE_PORT:-3001}
      - AUTO_SCAN_ENABLED=true
      - SCAN_INTERVAL_SECONDS=300
      - MAX_HISTORY_ENTRIES=1000
      - MAX_HISTORY_AGE_HOURS=24
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
    networks:
      - trading-net
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    depends_on:
      - data-service
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:3006/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  # TCN Training Service - Dedicated training container (LOW PRIORITY)
  # Runs separately from inference to prevent blocking API requests
  tcn-train-service:
    build:
      context: .
      dockerfile: docker/services/tcn-train/Dockerfile
      args:
        - SERVICE_PORT=${TCN_TRAIN_SERVICE_PORT:-3013}
    container_name: trading-tcn-train
    runtime: nvidia
    ports:
      - "${TCN_TRAIN_SERVICE_PORT:-3013}:${TCN_TRAIN_SERVICE_PORT:-3013}"
    volumes:
      - tcn-models:/app/data/models/tcn
      - symbols-data:/app/data/symbols
      - ./src/services/tcn_train_app:/app/src/services/tcn_train_app:ro
      - ./src/services/data_gateway_service.py:/app/src/services/data_gateway_service.py:ro
      - ./src/shared:/app/src/shared:ro
      - ./src/config:/app/src/config:ro
      - logs-data:/app/logs
    environment:
      - SERVICE_NAME=tcn-train
      - PORT=${TCN_TRAIN_SERVICE_PORT:-3013}
      - ROOT_PATH=/tcn-train
      - DATA_SERVICE_URL=http://trading-data:${DATA_SERVICE_PORT:-3001}
      - TCN_SERVICE_URL=http://trading-tcn:${TCN_SERVICE_PORT:-3003}
      - TCN_AUTO_TRAIN=true
      - TCN_MODEL_DIR=/app/data/models/tcn
      # Limit CPU threads for training
      - OMP_NUM_THREADS=4
      - MKL_NUM_THREADS=4
      - OPENBLAS_NUM_THREADS=4
      - NUMEXPR_MAX_THREADS=4
    networks:
      - trading-net
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    depends_on:
      - data-service
      - tcn-service
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${TCN_TRAIN_SERVICE_PORT:-3013}/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s

  # Candlestick Training Service - Dedicated training container (LOW PRIORITY)
  # Port 3016 - Trains TCN models for candlestick pattern recognition
  candlestick-train-service:
    build:
      context: .
      dockerfile: docker/services/candlestick-train/Dockerfile
    container_name: trading-candlestick-train
    ports:
      - "${CANDLESTICK_TRAIN_SERVICE_PORT:-3016}:${CANDLESTICK_TRAIN_SERVICE_PORT:-3016}"
    volumes:
      - candlestick-models:/app/models
      - candlestick-data:/app/data
      - ./src/services/candlestick_train_app:/app/src/services/candlestick_train_app:ro
      - logs-data:/app/logs
    environment:
      - SERVICE_NAME=candlestick-train
      - PORT=${CANDLESTICK_TRAIN_SERVICE_PORT:-3016}
      - ROOT_PATH=/candlestick-train
      - DATA_SERVICE_URL=http://trading-data:${DATA_SERVICE_PORT:-3001}
      - CANDLESTICK_SERVICE_URL=http://trading-candlestick:${CANDLESTICK_SERVICE_PORT:-3006}
      - MODEL_DIR=/app/models
      - DATA_DIR=/app/data
      - SCHEDULED_TRAINING_ENABLED=false
      - TRAINING_INTERVAL_HOURS=24
      - TRAINING_HOUR_UTC=2
      # Limit CPU threads for training
      - OMP_NUM_THREADS=2
      - MKL_NUM_THREADS=2
      - OPENBLAS_NUM_THREADS=2
      - NUMEXPR_MAX_THREADS=2
    networks:
      - trading-net
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    depends_on:
      - data-service
      - candlestick-service
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:3016/health')"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s

  # NHITS Training Service - Dedicated training container (LOW PRIORITY)
  # Port 3012 - Trains NHITS price forecast models
  nhits-train-service:
    build:
      context: .
      dockerfile: docker/services/nhits-train/Dockerfile
      args:
        - SERVICE_PORT=${NHITS_TRAIN_SERVICE_PORT:-3012}
    container_name: trading-nhits-train
    runtime: nvidia
    ports:
      - "${NHITS_TRAIN_SERVICE_PORT:-3012}:${NHITS_TRAIN_SERVICE_PORT:-3012}"
    volumes:
      - nhits-models:/app/data/models/nhits
      - symbols-data:/app/data/symbols
      - ./src/services/nhits_train_app:/app/src/services/nhits_train_app:ro
      - ./src/services/data_gateway_service.py:/app/src/services/data_gateway_service.py:ro
      - ./src/shared:/app/src/shared:ro
      - ./src/config:/app/src/config:ro
      - logs-data:/app/logs
    environment:
      - SERVICE_NAME=nhits-train
      - PORT=${NHITS_TRAIN_SERVICE_PORT:-3012}
      - ROOT_PATH=/nhits-train
      - DATA_SERVICE_URL=http://trading-data:${DATA_SERVICE_PORT:-3001}
      - NHITS_SERVICE_URL=http://trading-nhits:${NHITS_SERVICE_PORT:-3002}
      - MODEL_DIR=/app/data/models/nhits
      # Limit CPU threads for training
      - OMP_NUM_THREADS=4
      - MKL_NUM_THREADS=4
      - OPENBLAS_NUM_THREADS=4
      - NUMEXPR_MAX_THREADS=4
    networks:
      - trading-net
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    depends_on:
      - data-service
      - nhits-service
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 16G
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${NHITS_TRAIN_SERVICE_PORT:-3012}/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s

  # CNN-LSTM Multi-Task Service - Hybrid CNN-LSTM for Multi-Task Predictions (Port 3007)
  # Combines CNN for local features with LSTM for sequential processing
  cnn-lstm-service:
    build:
      context: .
      dockerfile: docker/services/cnn-lstm/Dockerfile
      args:
        - SERVICE_PORT=${CNN_LSTM_SERVICE_PORT:-3007}
    container_name: trading-cnn-lstm
    runtime: nvidia
    ports:
      - "${CNN_LSTM_SERVICE_PORT:-3007}:${CNN_LSTM_SERVICE_PORT:-3007}"
    volumes:
      - cnn-lstm-models:/app/data/models/cnn-lstm
      - cnn-lstm-data:/app/data
      - symbols-data:/app/data/symbols
      - logs-data:/app/logs
    environment:
      - SERVICE_NAME=cnn-lstm
      - PORT=${CNN_LSTM_SERVICE_PORT:-3007}
      - ROOT_PATH=/cnn-lstm
      - DATA_SERVICE_URL=http://trading-data:${DATA_SERVICE_PORT:-3001}
      - MODEL_DIR=/app/data/models/cnn-lstm
      - DATA_DIR=/app/data
      # Self-Learning Configuration
      - CNN_LSTM_TRAIN_SERVICE_URL=http://trading-cnn-lstm-train:${CNN_LSTM_TRAIN_SERVICE_PORT:-3017}
      - AUTO_BACKTEST_ENABLED=${CNN_LSTM_AUTO_BACKTEST_ENABLED:-true}
      - AUTO_BACKTEST_INTERVAL_HOURS=${CNN_LSTM_AUTO_BACKTEST_INTERVAL:-6}
      - AUTO_RETRAIN_ENABLED=${CNN_LSTM_AUTO_RETRAIN_ENABLED:-true}
      - AUTO_RETRAIN_ACCURACY_THRESHOLD=${CNN_LSTM_RETRAIN_ACCURACY_THRESHOLD:-60.0}
      - AUTO_RETRAIN_MIN_SAMPLES=${CNN_LSTM_RETRAIN_MIN_SAMPLES:-20}
      - AUTO_RETRAIN_COOLDOWN_HOURS=${CNN_LSTM_RETRAIN_COOLDOWN_HOURS:-24}
      # Continuous Optimization (Drift Detection)
      - CONTINUOUS_OPTIMIZATION_ENABLED=${CNN_LSTM_CONTINUOUS_ENABLED:-true}
      - DRIFT_DETECTION_WINDOW=${CNN_LSTM_DRIFT_WINDOW:-20}
      - DRIFT_THRESHOLD=${CNN_LSTM_DRIFT_THRESHOLD:-15.0}
      - IMMEDIATE_RETRAIN_ON_DRIFT=${CNN_LSTM_IMMEDIATE_RETRAIN:-true}
      # Limit CPU threads
      - OMP_NUM_THREADS=2
      - MKL_NUM_THREADS=2
      - OPENBLAS_NUM_THREADS=2
      - NUMEXPR_MAX_THREADS=2
    networks:
      - trading-net
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    depends_on:
      - data-service
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 6G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${CNN_LSTM_SERVICE_PORT:-3007}/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # CNN-LSTM Training Service - Dedicated training container (LOW PRIORITY)
  # Port 3017 - Trains CNN-LSTM Multi-Task models
  cnn-lstm-train-service:
    build:
      context: .
      dockerfile: docker/services/cnn-lstm-train/Dockerfile
      args:
        - SERVICE_PORT=${CNN_LSTM_TRAIN_SERVICE_PORT:-3017}
    container_name: trading-cnn-lstm-train
    runtime: nvidia
    ports:
      - "${CNN_LSTM_TRAIN_SERVICE_PORT:-3017}:${CNN_LSTM_TRAIN_SERVICE_PORT:-3017}"
    volumes:
      - cnn-lstm-models:/app/data/models/cnn-lstm
      - symbols-data:/app/data/symbols
      - logs-data:/app/logs
    environment:
      - SERVICE_NAME=cnn-lstm-train
      - PORT=${CNN_LSTM_TRAIN_SERVICE_PORT:-3017}
      - ROOT_PATH=/cnn-lstm-train
      - DATA_SERVICE_URL=http://trading-data:${DATA_SERVICE_PORT:-3001}
      - CNN_LSTM_SERVICE_URL=http://trading-cnn-lstm:${CNN_LSTM_SERVICE_PORT:-3007}
      - MODEL_DIR=/app/data/models/cnn-lstm
      - NICE_PRIORITY=19
      # Limit CPU threads for training
      - OMP_NUM_THREADS=4
      - MKL_NUM_THREADS=4
      - OPENBLAS_NUM_THREADS=4
      - NUMEXPR_MAX_THREADS=4
    networks:
      - trading-net
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    depends_on:
      - data-service
      - cnn-lstm-service
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 12G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${CNN_LSTM_TRAIN_SERVICE_PORT:-3017}/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s

  # HMM Training Service - Dedicated training container (LOW PRIORITY)
  # Port 3014 - Trains HMM regime detection and LightGBM scorer models
  hmm-train-service:
    build:
      context: .
      dockerfile: docker/services/hmm-train/Dockerfile
      args:
        - SERVICE_PORT=${HMM_TRAIN_SERVICE_PORT:-3014}
    container_name: trading-hmm-train
    ports:
      - "${HMM_TRAIN_SERVICE_PORT:-3014}:${HMM_TRAIN_SERVICE_PORT:-3014}"
    volumes:
      - hmm-models:/app/data/models/hmm
      - symbols-data:/app/data/symbols
      - ./src/services/hmm_train_app:/app/src/services/hmm_train_app:ro
      - ./src/services/data_gateway_service.py:/app/src/services/data_gateway_service.py:ro
      - ./src/shared:/app/src/shared:ro
      - ./src/config:/app/src/config:ro
      - logs-data:/app/logs
    environment:
      - SERVICE_NAME=hmm-train
      - PORT=${HMM_TRAIN_SERVICE_PORT:-3014}
      - ROOT_PATH=/hmm-train
      - DATA_SERVICE_URL=http://trading-data:${DATA_SERVICE_PORT:-3001}
      - HMM_SERVICE_URL=http://trading-hmm:${HMM_SERVICE_PORT:-3004}
      - MODEL_DIR=/app/data/models/hmm
    networks:
      - trading-net
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    depends_on:
      - data-service
      - hmm-service
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${HMM_TRAIN_SERVICE_PORT:-3014}/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s

  # =========================================================================
  # MONITORING & ORCHESTRATION
  # =========================================================================

  # Watchdog Service - Monitoring & Training Orchestrator (Port 3010)
  watchdog-service:
    build:
      context: .
      dockerfile: docker/services/watchdog/Dockerfile
      args:
        - SERVICE_PORT=${WATCHDOG_SERVICE_PORT:-3010}
    container_name: trading-watchdog
    ports:
      - "${WATCHDOG_SERVICE_PORT:-3010}:${WATCHDOG_SERVICE_PORT:-3010}"
    volumes:
      - watchdog-data:/app/data
      - ./src/services/watchdog_app:/app/src/services/watchdog_app:ro
      - ./src/shared:/app/src/shared:ro
      - ./src/config:/app/src/config:ro
      - logs-data:/app/logs
    environment:
      - SERVICE_NAME=watchdog
      - PORT=${WATCHDOG_SERVICE_PORT:-3010}
      - ROOT_PATH=/watchdog
      # Training service URLs for orchestrator
      - NHITS_TRAIN_URL=http://trading-nhits-train:${NHITS_TRAIN_SERVICE_PORT:-3012}
      - TCN_TRAIN_URL=http://trading-tcn-train:${TCN_TRAIN_SERVICE_PORT:-3013}
      - HMM_TRAIN_URL=http://trading-hmm-train:${HMM_TRAIN_SERVICE_PORT:-3014}
      - CANDLESTICK_TRAIN_URL=http://trading-candlestick-train:${CANDLESTICK_TRAIN_SERVICE_PORT:-3016}
      - CNN_LSTM_TRAIN_URL=http://trading-cnn-lstm-train:${CNN_LSTM_TRAIN_SERVICE_PORT:-3017}
      # Monitoring service URLs
      - DATA_SERVICE_URL=http://trading-data:${DATA_SERVICE_PORT:-3001}
      - NHITS_SERVICE_URL=http://trading-nhits:${NHITS_SERVICE_PORT:-3002}
      - TCN_SERVICE_URL=http://trading-tcn:${TCN_SERVICE_PORT:-3003}
      - HMM_SERVICE_URL=http://trading-hmm:${HMM_SERVICE_PORT:-3004}
      - EMBEDDER_SERVICE_URL=http://trading-embedder:${EMBEDDER_SERVICE_PORT:-3005}
      - RAG_SERVICE_URL=http://trading-rag:${RAG_SERVICE_PORT:-3008}
      - LLM_SERVICE_URL=http://trading-llm:${LLM_SERVICE_PORT:-3009}
      # Telegram configuration
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN:-}
      - TELEGRAM_CHAT_IDS=${TELEGRAM_CHAT_IDS:-}
    networks:
      - trading-net
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    depends_on:
      - data-service
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${WATCHDOG_SERVICE_PORT:-3010}/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  # Trading Workplace Service - Setup Aggregation & Multi-Signal Scoring (Port 3020)
  # Aggregates predictions from all ML services and provides trading setup recommendations
  workplace-service:
    build:
      context: .
      dockerfile: docker/services/workplace/Dockerfile
      args:
        - SERVICE_PORT=${WORKPLACE_SERVICE_PORT:-3020}
    container_name: trading-workplace
    ports:
      - "${WORKPLACE_SERVICE_PORT:-3020}:${WORKPLACE_SERVICE_PORT:-3020}"
    volumes:
      - workplace-data:/app/data
      - ./src/services/workplace_app:/app/src/services/workplace_app:ro
      - ./src/shared:/app/src/shared:ro
      - ./src/config:/app/src/config:ro
      - ./src/utils:/app/src/utils:ro
      - logs-data:/app/logs
    environment:
      - SERVICE_NAME=workplace
      - PORT=${WORKPLACE_SERVICE_PORT:-3020}
      - ROOT_PATH=/workplace
      # ML Service URLs for signal aggregation
      - DATA_SERVICE_URL=http://trading-data:${DATA_SERVICE_PORT:-3001}
      - NHITS_SERVICE_URL=http://trading-nhits:${NHITS_SERVICE_PORT:-3002}
      - TCN_SERVICE_URL=http://trading-tcn:${TCN_SERVICE_PORT:-3003}
      - HMM_SERVICE_URL=http://trading-hmm:${HMM_SERVICE_PORT:-3004}
      - CANDLESTICK_SERVICE_URL=http://trading-candlestick:${CANDLESTICK_SERVICE_PORT:-3006}
      - CNN_LSTM_SERVICE_URL=http://trading-cnn-lstm:${CNN_LSTM_SERVICE_PORT:-3007}
      - RAG_SERVICE_URL=http://trading-rag:${RAG_SERVICE_PORT:-3008}
      - LLM_SERVICE_URL=http://trading-llm:${LLM_SERVICE_PORT:-3009}
      # Scanner configuration
      - WORKPLACE_SCAN_INTERVAL_SECONDS=${WORKPLACE_SCAN_INTERVAL:-60}
      - WORKPLACE_AUTO_SCAN_ENABLED=${WORKPLACE_AUTO_SCAN:-true}
    networks:
      - trading-net
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    depends_on:
      - data-service
      - nhits-service
      - hmm-service
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${WORKPLACE_SERVICE_PORT:-3020}/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

# =============================================================================
# VOLUMES
# =============================================================================
volumes:
  # Redis Cache Volume
  redis-data:
    driver: local

  # NHITS Service Volumes
  nhits-models:
    driver: local
  nhits-feedback:
    driver: local
  nhits-metrics:
    driver: local

  # Data Service Volumes
  data-storage:
    driver: local
  symbols-data:
    driver: local
  faiss-data:
    driver: local

  # TCN Service Volumes
  tcn-models:
    driver: local
  tcn-data:
    driver: local

  # Candlestick Service Volumes
  candlestick-models:
    driver: local
  candlestick-data:
    driver: local

  # HMM Service Volumes
  hmm-models:
    driver: local

  # CNN-LSTM Service Volumes
  cnn-lstm-models:
    driver: local
  cnn-lstm-data:
    driver: local

  # Embedder Service Volumes
  embedder-models:
    driver: local
  embedder-cache:
    driver: local

  # RAG Service Volumes
  rag-faiss:
    driver: local

  # Shared Logs Volume
  logs-data:
    driver: local

  # Watchdog Service Volume
  watchdog-data:
    driver: local

  # Trading Workplace Service Volume
  workplace-data:
    driver: local

# =============================================================================
# NETWORKS
# =============================================================================
networks:
  trading-net:
    driver: bridge
