services:
  # Frontend - API Gateway & Dashboard (Port 3000)
  frontend:
    build:
      context: .
      dockerfile: docker/services/frontend/Dockerfile
    container_name: trading-frontend
    ports:
      - "3000:80"
    depends_on:
      - nhits-service
      - llm-service
      - data-service
    networks:
      - trading-net
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 3s
      retries: 3

  # NHITS Service - Training & Forecasting (Port 3001)
  nhits-service:
    build:
      context: .
      dockerfile: docker/services/nhits/Dockerfile
    container_name: trading-nhits
    runtime: nvidia
    ports:
      - "3001:3001"
    volumes:
      - models-data:/app/data/models
      - ./src:/app/src:ro
      - ./logs:/app/logs
    environment:
      - SERVICE_NAME=nhits
      - PORT=3001
      - NHITS_USE_GPU=1
      - EASYINSIGHT_API_URL=${EASYINSIGHT_API_URL:-http://10.1.19.102:3000/api}
      - NHITS_AUTO_RETRAIN_DAYS=${NHITS_AUTO_RETRAIN_DAYS:-7}
      - OLLAMA_HOST=http://host.docker.internal:11434
    networks:
      - trading-net
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 16G
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # LLM Service - Analysis & RAG (Port 3002)
  llm-service:
    build:
      context: .
      dockerfile: docker/services/llm/Dockerfile
    container_name: trading-llm
    runtime: nvidia
    ports:
      - "3002:3002"
    volumes:
      - rag-data:/app/data/rag
      - ./src:/app/src:ro
      - ./logs:/app/logs
    environment:
      - SERVICE_NAME=llm
      - PORT=3002
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.1:70b}
      - OLLAMA_HOST=http://host.docker.internal:11434
      - FAISS_USE_GPU=1
      - EMBEDDING_DEVICE=cuda
      - EASYINSIGHT_API_URL=${EASYINSIGHT_API_URL:-http://10.1.19.102:3000/api}
    networks:
      - trading-net
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 32G
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Data Service - Symbols, Strategies, Sync (Port 3003)
  data-service:
    build:
      context: .
      dockerfile: docker/services/data/Dockerfile
    container_name: trading-data
    ports:
      - "3003:3003"
    volumes:
      - ./src:/app/src:ro
      - ./logs:/app/logs
      - ./data/symbols:/app/data/symbols
    environment:
      - SERVICE_NAME=data
      - PORT=3003
      - EASYINSIGHT_API_URL=${EASYINSIGHT_API_URL:-http://10.1.19.102:3000/api}
      - OLLAMA_HOST=http://host.docker.internal:11434
    networks:
      - trading-net
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 4G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3003/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

volumes:
  models-data:
    driver: local
  rag-data:
    driver: local

networks:
  trading-net:
    driver: bridge
